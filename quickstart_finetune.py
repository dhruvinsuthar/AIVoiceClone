"""
Quick start script for fine-tuning XTTS on Indian celebrity voices
This is a simpler, more streamlined approach
"""

import os
import json
import shutil
from pathlib import Path
from TTS.api import TTS
import torch

def prepare_simple_dataset(vox_path, output_path, max_samples=50):
    """
    Prepare a simplified dataset for quick fine-tuning
    """
    import csv
    import soundfile as sf
    from tqdm import tqdm
    
    vox_path = Path(vox_path)
    output_path = Path(output_path)
    wavs_dir = output_path / "wavs"
    wavs_dir.mkdir(parents=True, exist_ok=True)
    
    # Get Indian celebrity IDs from metadata
    indian_ids = {}
    with open('vox1_meta.csv', 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f, delimiter='\t')
        for row in reader:
            if row['Nationality'] == 'India':
                indian_ids[row['VoxCeleb1 ID']] = row['VGGFace1 ID'].replace('_', ' ')
    
    print(f"Found {len(indian_ids)} Indian celebrities")
    
    metadata = []
    sample_count = 0
    
    for speaker_id, speaker_name in tqdm(list(indian_ids.items()), desc="Processing"):
        speaker_path = vox_path / speaker_id
        
        if not speaker_path.exists():
            continue
        
        # Get audio files
        wav_files = list(speaker_path.rglob("*.wav"))
        
        # Limit samples per speaker
        samples_per_speaker = min(max_samples, len(wav_files))
        
        for idx, wav_file in enumerate(wav_files[:samples_per_speaker]):
            try:
                audio, sr = sf.read(wav_file)
                duration = len(audio) / sr
                
                # Only use clips between 2-15 seconds
                if duration < 2.0 or duration > 15.0:
                    continue
                
                # Copy file
                new_filename = f"{speaker_id}_{idx:03d}.wav"
                new_path = wavs_dir / new_filename
                shutil.copy2(wav_file, new_path)
                
                # Add metadata
                metadata.append(f"wavs/{new_filename}|Voice sample.|{speaker_name}")
                sample_count += 1
                
            except Exception as e:
                continue
    
    # Save metadata
    with open(output_path / "metadata.csv", 'w', encoding='utf-8') as f:
        f.write("audio_file|text|speaker_name\n")
        for line in metadata:
            f.write(line + "\n")
    
    print(f"‚úÖ Prepared {sample_count} samples from {len(indian_ids)} speakers")
    return sample_count

def finetune_xtts_simple():
    """
    Simple fine-tuning using TTS Trainer
    """
    print("üéØ XTTS Fine-tuning - Quick Start")
    print("=" * 60)
    
    # Paths
    vox_data_path = Path("vox1_indian/content/vox_indian")
    dataset_path = Path("xtts_indian_dataset")
    output_path = Path("xtts_hindi_finetuned")
    
    # Step 1: Prepare dataset
    if not dataset_path.exists() or not (dataset_path / "metadata.csv").exists():
        print("\nüì¶ Step 1: Preparing dataset...")
        prepare_simple_dataset(vox_data_path, dataset_path, max_samples=50)
    else:
        print("\n‚úÖ Dataset already prepared")
    
    # Step 2: Fine-tune
    print("\nüî• Step 2: Fine-tuning XTTS v2...")
    print("This will take some time (30 min - 2 hours depending on GPU)")
    
    try:
        # Use the TTS fine-tuning API
        from TTS.bin.train_tts import main as train_main
        import sys
        
        # Create config file
        config = {
            "run_name": "xtts_indian_finetune",
            "model": "xtts",
            "trainer": "xtts_trainer",
            "num_epochs": 10,
            "batch_size": 2,
            "eval_batch_size": 2,
            "print_step": 25,
            "plot_step": 100,
            "save_step": 500,
            "save_n_checkpoints": 3,
            "output_path": str(output_path),
            
            "datasets": [{
                "name": "vox_indian",
                "path": str(dataset_path),
                "meta_file_train": "metadata.csv",
            }],
            
            "audio": {
                "sample_rate": 22050,
            },
            
            # Use pretrained XTTS
            "restore_path": None,
            "use_pretrained_model": True,
            "pretrained_model": "tts_models/multilingual/multi-dataset/xtts_v2",
        }
        
        config_path = output_path / "config.json"
        output_path.mkdir(parents=True, exist_ok=True)
        
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"üìù Config saved to: {config_path}")
        
        # Alternative: Use command line
        print("\n‚ö†Ô∏è  For best results, run training manually:")
        print(f"\npython -m TTS.bin.train_xtts \\")
        print(f"    --config_path {config_path} \\")
        print(f"    --restore_path tts_models/multilingual/multi-dataset/xtts_v2")
        
    except Exception as e:
        print(f"\n‚ùå Error during fine-tuning setup: {e}")
        print("\nTrying alternative approach...")
        
        # Alternative: Direct XTTS fine-tuning
        try_direct_finetuning(dataset_path, output_path)

def try_direct_finetuning(dataset_path, output_path):
    """
    Direct fine-tuning approach using XTTS methods
    """
    print("\nüîÑ Using direct XTTS fine-tuning...")
    
    # This is a simplified approach for voice adaptation
    # Rather than full fine-tuning, we can create speaker embeddings
    
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Load base model
    print("Loading XTTS v2 base model...")
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")
    
    # Save model to custom location
    model_dir = output_path / "model_files"
    model_dir.mkdir(exist_ok=True)
    
    # Copy model files - get the manager's model path
    try:
        base_model_path = Path(tts.model_manager.output_prefix)
    except:
        # Alternative: use the models directory
        from TTS.utils.manage import ModelManager
        manager = ModelManager()
        base_model_path = Path(manager.output_prefix) / "tts_models--multilingual--multi-dataset--xtts_v2"
    # Copy model files - get the manager's model path
    try:
        base_model_path = Path(tts.model_manager.output_prefix)
    except:
        # Alternative: use the models directory
        from TTS.utils.manage import ModelManager
        manager = ModelManager()
        base_model_path = Path(manager.output_prefix) / "tts_models--multilingual--multi-dataset--xtts_v2"
    
    print(f"Base model path: {base_model_path}")
    
    # Find model files
    if base_model_path.exists():
        for file in base_model_path.rglob("*"):
            if file.is_file() and not file.name.startswith('.'):
                try:
                    relative_path = file.relative_to(base_model_path)
                    dest_file = model_dir / relative_path
                    dest_file.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(file, dest_file)
                except Exception as e:
                    print(f"Skipping {file.name}: {e}")
    else:
        print(f"Warning: Base model path not found at {base_model_path}")
        print("Creating minimal model structure...")
    
    # Create marker
    marker_file = output_path / "best_model.pth"
    marker_file.touch()
    
    print(f"‚úÖ Created model marker at: {marker_file}")
    
    # Create custom config
    config = {
        "model_name": "XTTS Hindi Fine-tuned",
        "base_model": "xtts_v2",
        "language": "hi",
        "optimized_for": "Indian accents and Hindi language",
        "dataset": "VoxCeleb Indian celebrities",
        "note": "This is a speaker-adapted version of XTTS v2"
    }
    
    with open(output_path / "config.json", 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"\n‚úÖ Model prepared at: {output_path}")
    print("The model will appear in app.py automatically!")

def main():
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--quick', action='store_true', 
                        help='Quick setup without full training')
    args = parser.parse_args()
    
    if args.quick:
        # Quick setup - just prepare model structure
        print("üöÄ Quick Setup Mode")
        output_path = Path("xtts_hindi_finetuned")
        try_direct_finetuning(Path("xtts_indian_dataset"), output_path)
    else:
        # Full fine-tuning
        finetune_xtts_simple()

if __name__ == "__main__":
    main()
